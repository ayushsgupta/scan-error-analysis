{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/miniconda3/envs/scan/lib/python3.8/site-packages/pymatgen/ext/matproj.py:454: DeprecationWarning:\n",
      "\n",
      "__init__ is deprecated\n",
      "MaterialsProjectCompatibility will be updated with new correction classes as well as new values of corrections and uncertainties in 2020\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successfully loaded\n"
     ]
    }
   ],
   "source": [
    "%run imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run classifiers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem_featurizer = ElementFraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_formula_ids = loadfn('data/binary_formulas_ids.json')\n",
    "binary_ids = list(binary_formula_ids.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elfcars = loadfn('data/elfcars.json')\n",
    "ids = [i for i in elfcars.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 427/427 [00:00<00:00, 1718.10it/s]\n"
     ]
    }
   ],
   "source": [
    "skips = ['7356']\n",
    "vector_list = []\n",
    "for i in tqdm(binary_ids):\n",
    "    i = str(i)\n",
    "    if i in skips:\n",
    "        new_vec = None\n",
    "    else:\n",
    "        new_vec = elem_featurizer.featurize(Composition(elfcars[i].structure.composition.reduced_formula))\n",
    "    if new_vec is not None:\n",
    "        vector_list.append(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 103)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.vstack(vector_list)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.load('data/b.npy')\n",
    "b = np.abs(b) > 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426 total data points, 383 (90%) used for model development\n"
     ]
    }
   ],
   "source": [
    "N = A.shape[0]\n",
    "n = int(0.9*N)\n",
    "print(N, 'total data points,', n, '(90%) used for model development')\n",
    "A_train, A_test = A[:n], A[n:]\n",
    "b_train, b_test = b[:n], b[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6744186046511628"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(A_train, b_train)\n",
    "accuracy_score(classifier.predict(A_test), b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7136150234741784"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(b) / len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426 total data points, 383 (90%) used for model development\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6511627906976745"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Arand = np.random.rand(426, 30)\n",
    "N = Arand.shape[0]\n",
    "n = int(0.9*N)\n",
    "print(N, 'total data points,', n, '(90%) used for model development')\n",
    "A_train, A_test = Arand[:n], Arand[n:]\n",
    "b_train, b_test = b[:n], b[n:]\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(A_train, b_train)\n",
    "accuracy_score(classifier.predict(A_test), b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bader_statistics = loadfn('data/bader_statistics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_elfcars = {}\n",
    "element_formulas_ids = loadfn('data/element_formulas_ids.json')\n",
    "\n",
    "for f, ID in element_formulas_ids.items():\n",
    "    element_elfcars[f] = elfcars[str(ID)]\n",
    "    \n",
    "element_statistics = {}\n",
    "\n",
    "for f in element_elfcars.keys():\n",
    "    spatial_data = element_elfcars[f].get_alpha().data['total'].flatten()\n",
    "    element_statistics[f] = [np.mean(spatial_data), np.std(spatial_data), np.max(spatial_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipper(l1, l2):\n",
    "    i1, i2 = iter(l1), iter(l2)\n",
    "    for _ in range(max(len(l1), len(l2))):\n",
    "        try:\n",
    "            yield next(i1)\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        try:\n",
    "            yield next(i2)\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        \n",
    "zip_lists = lambda l1, l2: [x for x in zipper(l1, l2)]   \n",
    "flatten_list = lambda l: [y for x in l for y in x]\n",
    "\n",
    "def trim_vector(vector, length, ndescriptors):\n",
    "    if len(vector) > length:\n",
    "        vector = vector[:length]\n",
    "    elif len(vector) < length:\n",
    "        idx = 0\n",
    "        while len(vector) < length:\n",
    "            vector += vector[idx:idx+ndescriptors]\n",
    "            idx += ndescriptors\n",
    "    return vector\n",
    "\n",
    "skips = ['7356']\n",
    "\n",
    "def add_general_features(vector, cation, anion, nbader_wells):\n",
    "    pass\n",
    "\n",
    "def feature_vector(i, num_wells=2):\n",
    "    i = str(i)\n",
    "    if i in skips:\n",
    "        return None\n",
    "    cation, anion = [str(e) for e in elfcars[i].structure.composition.elements]\n",
    "    bader_stats = bader_statistics[i]\n",
    "    cation_vectors, anion_vectors = [], []\n",
    "    for well in bader_stats:\n",
    "        f = [*well.keys()][0]\n",
    "        vi = np.array(well[f]) - np.array(element_statistics[f])\n",
    "        if f == cation:\n",
    "            cation_vectors.append(vi)\n",
    "        elif f == anion:\n",
    "            anion_vectors.append(vi)\n",
    "        else:\n",
    "            raise ValueError('Atom does not match either cation or anion')\n",
    "    ndescriptors = len(cation_vectors[0])\n",
    "    length = num_wells * ndescriptors\n",
    "    vector = np.array(trim_vector(flatten_list(zip_lists(cation_vectors, anion_vectors)), length, ndescriptors))\n",
    "#     reshaped = vector.reshape((-1,3))\n",
    "#     diffsquared_cat_an = np.mean(cation_vectors, axis=0)**2 - np.mean(anion_vectors, axis=0)**2\n",
    "#     vector = np.append(vector, diffsquared_cat_an)    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.50969334e+00,  4.92817031e-01, -7.41933043e-01],\n",
       "       [-1.67430955e+02, -3.27421624e+02, -3.03831668e+03]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector(6405).reshape((-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 427/427 [00:00<00:00, 7897.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vector_list = []\n",
    "for i in tqdm(binary_ids):\n",
    "    new_vec = feature_vector(i)\n",
    "    if new_vec is not None:\n",
    "        vector_list.append(new_vec)\n",
    "Asmall = np.vstack(vector_list)\n",
    "print(Asmall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426 total data points, 383 (90%) used for model development\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6744186046511628"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = Asmall.shape[0]\n",
    "n = int(0.9*N)\n",
    "print(N, 'total data points,', n, '(90%) used for model development')\n",
    "A_train, A_test = Asmall[:n], Asmall[n:]\n",
    "b_train, b_test = b[:n], b[n:]\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(A_train, b_train)\n",
    "accuracy_score(classifier.predict(A_test), b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda: scan)",
   "language": "python",
   "name": "scan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
